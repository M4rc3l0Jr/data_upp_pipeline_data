{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M4rc3l0Jr/data_upp_pipeline_data/blob/main/newdatapipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6WVe5nFcLJ6",
        "outputId": "99613dc1-2711-4484-d579-af3272318c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "# imports\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.auth import credentials\n",
        "from google.auth import default, iam\n",
        "from google.auth.credentials import with_scopes_if_required\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import time\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "import random\n",
        "import string\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data_atual = datetime.today().date()\n",
        "\n",
        "# authentication with google\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "creds = with_scopes_if_required(creds, ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive'])\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "drive_service = build('drive', 'v3', credentials=creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-oIkm57m1Yt"
      },
      "outputs": [],
      "source": [
        "# method to all folders from drive that we need\n",
        "def get_all_folders(name):\n",
        "  # listing all folders\n",
        "  results = drive_service.files().list(q=\"mimeType='application/vnd.google-apps.folder'\", pageSize=1000, fields=\"nextPageToken, files(id, name)\").execute()\n",
        "  items = results.get('files', [])\n",
        "\n",
        "  for item in items:\n",
        "    if 'tabela_de_reatailer' in item['name']:\n",
        "      folder_id_retailer_table = item['id']\n",
        "      file_retailer_table = drive_service.files().list(q=f\"'{folder_id_retailer_table}' in parents\",\n",
        "                                      fields='files(name)').execute()\n",
        "\n",
        "      # extrain file name\n",
        "      file_names = [file['name'] for file in file_retailer_table.get('files', [])]\n",
        "      file_names = file_names[0]\n",
        "      if 'retailer' in file_names:\n",
        "        data_retailer_table = gc.open(f'{file_names}').sheet1\n",
        "        df_retailers = data_retailer_table.get_all_values()\n",
        "        df_retailers = pd.DataFrame(df_retailers[1:], columns=df_retailers[0])\n",
        "\n",
        "  folders = []\n",
        "\n",
        "  # verify if folder has name we need\n",
        "  for item in items:\n",
        "      if name in item['name']:\n",
        "        folders.append(item)\n",
        "\n",
        "  # remove folder raw\n",
        "  for item in folders:\n",
        "    if name == item['name']:\n",
        "      folder_id_raw = item['id']\n",
        "      folders.remove(item)\n",
        "\n",
        "  # return folder list\n",
        "  return folders, folder_id_raw, df_retailers\n",
        "\n",
        "# method to take archives of the folder\n",
        "def take_archives(folder_id):\n",
        "  files = drive_service.files().list(q=f\"'{folder_id}' in parents\",\n",
        "                                  fields='files(name)').execute()\n",
        "\n",
        "  # extrain file name\n",
        "  file_names = [file['name'] for file in files.get('files', [])]\n",
        "\n",
        "  # return file names\n",
        "  return file_names\n",
        "\n",
        "# method to read gsheets\n",
        "def read_gsheets(file_names):\n",
        "  df_registered = None\n",
        "  df_orders = None\n",
        "  for file in file_names:\n",
        "    if 'cadastro' in file:\n",
        "      # open file and convert in dataframe\n",
        "      data_registered = gc.open(f'{file}').sheet1\n",
        "      df_registered = data_registered.get_all_values()\n",
        "      df_registered = pd.DataFrame(df_registered[1:], columns=df_registered[0])\n",
        "      print('Tabela de clientes criada!')\n",
        "    else:\n",
        "      data_order = gc.open(f'{file}').sheet1\n",
        "      df_orders = data_order.get_all_values()\n",
        "      df_orders = pd.DataFrame(df_orders[1:], columns=df_orders[0])\n",
        "      print('Tabela de pedidos criada!')\n",
        "\n",
        "  # return df_registered and df_orders\n",
        "  return df_registered, df_orders\n",
        "\n",
        "def create_folder(folder_id, name_folder):\n",
        "  parent_folder_id = folder_id\n",
        "\n",
        "  folder_metadata = {\n",
        "      'name': name_folder,\n",
        "      'mimeType': 'application/vnd.google-apps.folder',\n",
        "      'parents': [parent_folder_id]\n",
        "  }\n",
        "\n",
        "  new_folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
        "  folder_raw_id = new_folder.get('id')\n",
        "\n",
        "  return folder_raw_id\n",
        "\n",
        "def create_gsheets(folder_id, name_sheets, df):\n",
        "\n",
        "  file_metadata = {\n",
        "      'name': name_sheets,\n",
        "      'parents': [folder_id],\n",
        "      'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "  }\n",
        "  spreadsheet = drive_service.files().create(body=file_metadata,\n",
        "                                              fields='id').execute()\n",
        "\n",
        "  sh = gc.open_by_key(spreadsheet['id'])\n",
        "\n",
        "  # Selecionando a primeira planilha na planilha\n",
        "  worksheet = sh.get_worksheet(0)\n",
        "\n",
        "  # Convertendo o DataFrame para uma lista de listas\n",
        "  data = df.values.tolist()\n",
        "\n",
        "  # Inserindo os dados na planilha\n",
        "  worksheet.clear()\n",
        "  worksheet.append_row(df.columns.tolist())\n",
        "\n",
        "  n_rows = 0\n",
        "\n",
        "  for row in data:\n",
        "      if (n_rows % 45) == 0:\n",
        "        time.sleep(45)\n",
        "      worksheet.append_row(row)\n",
        "      n_rows += 1\n",
        "\n",
        "def rename_columns(df):\n",
        "    '''Use this method to rename all columns to transform 'Column Name' in 'column_name'\n",
        "        Args:\n",
        "            df: Dataframe you want rename columns\n",
        "        Returns:\n",
        "            df: Dataframe with raname columns\n",
        "    '''\n",
        "    columns = df.columns # take all df columns\n",
        "\n",
        "    for column in columns: # loop to rename each column\n",
        "\n",
        "        column_rename = unidecode(column).lower() # column in lowercase\n",
        "        column_rename = re.sub(r'[^a-zA-Z0-9\\s]', '', column_rename) # remove all special character\n",
        "        column_rename = column_rename.replace(' ', '_') # change ' ' to '_'\n",
        "        df.rename(columns={f'{column}':f'{column_rename}'}, inplace=True)  # rename column\n",
        "\n",
        "    return df\n",
        "\n",
        "def format_date(date):\n",
        "    ''' Use this method to transform '%m-%d-%Y' in '%Y-%m-%d'\n",
        "        Args:\n",
        "            date: date column, this column need is in string format\n",
        "        Returns:\n",
        "            date: in format '%Y-%m-%d'\n",
        "    '''\n",
        "    # verify if the value is null, case is null return null\n",
        "    if pd.notnull(date):\n",
        "        # Check if the input is already a datetime object\n",
        "        if isinstance(date, pd.Timestamp):\n",
        "            return date.strftime(\"%Y-%m-%d\")  # Format directly\n",
        "        else:\n",
        "            return datetime.strptime(date, \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def remove_number_address(full_address):\n",
        "    '''Use this method to extract the number of the address\n",
        "        Args:\n",
        "            full_address: full address\n",
        "        Returns:\n",
        "            number: return full address number\n",
        "    '''\n",
        "    match = re.search(r'\\d+', full_address) # to do a verify if the value has number\n",
        "\n",
        "    if match: # case it's has return first sequence\n",
        "        number = match.group()\n",
        "        return number\n",
        "\n",
        "    else: # case not, return 'sem_numero'\n",
        "        number = 'sem_numero'\n",
        "        return number\n",
        "\n",
        "def remove_complement_address(full_address):\n",
        "    '''Use this method to extract the complemt of the address\n",
        "        Args:\n",
        "            full_address: full addresss\n",
        "        Returns:\n",
        "            complement: return full address complement\n",
        "    '''\n",
        "    # Search for the first occurrence of one or more digits (\\d+) in the full_address string\n",
        "    match = re.search(r'\\d+', full_address)\n",
        "\n",
        "    # If a match is found:\n",
        "    if match:\n",
        "        # Get the index where the numeric characters end\n",
        "        index_numeric = match.end()\n",
        "\n",
        "        # Extract the part of the address string starting from the index where numeric characters end,\n",
        "        # removing any leading or trailing whitespace\n",
        "        complement = full_address[index_numeric:].strip()\n",
        "\n",
        "        # Return the extracted complement part of the address\n",
        "        return complement\n",
        "    # If no match is found:\n",
        "    else:\n",
        "        # Return the original full_address string\n",
        "        return full_address\n",
        "\n",
        "def format_address(street, number, complement):\n",
        "    '''Use this method to get correct address based in address data\n",
        "\n",
        "        df[['number', 'complement', 'street']] = df.apply(lambda row: format_address(row['street'], row['number'], row['complement']), axis=1)\n",
        "\n",
        "        Args:\n",
        "            street: df['street']\n",
        "            number: df['number']\n",
        "            complement: df['complement']\n",
        "        Return:\n",
        "            street: street data\n",
        "            number: number street\n",
        "            complement: complement street\n",
        "    '''\n",
        "    # concat all values to get full address and remove possible issues when this data is inputed\n",
        "    street = str(street)\n",
        "    number = str(number)\n",
        "    complement = str(complement)\n",
        "    full_address = street + ' ' + number + ' ' + complement\n",
        "    # remove address number to full_address\n",
        "    number = remove_number_address(full_address)\n",
        "    # recmove address complement to full_address\n",
        "    complement = remove_complement_address(full_address)\n",
        "    # take the name street\n",
        "    street = full_address.replace(number, '').replace(complement, '')\n",
        "    # return three values to three columns\n",
        "    return number, complement, street\n",
        "\n",
        "def household_type(complement):\n",
        "    '''Use this method to get household type\n",
        "\n",
        "        Args:\n",
        "            complement: df['complement']\n",
        "        Return:\n",
        "            household_type: home, apartment or others\n",
        "    '''\n",
        "    # to convert input in string and lowercase\n",
        "    complement = str(complement).lower()\n",
        "    # if complement has 'casa' or 'cs' in complement\n",
        "    if 'casa' in complement or 'cs' in complement:\n",
        "        # inpout 'casa' in variable\n",
        "        household = 'casa'\n",
        "    # if complement has ap or is a digit:\n",
        "    elif 'ap' in complement or complement.isdigit():\n",
        "        # input 'apartamento' in variable\n",
        "        household = 'apartamento'\n",
        "    # if complement dont have 'casa' or 'apartamento'\n",
        "    else:\n",
        "        # input 'outros' in avariable\n",
        "        household = 'outros'\n",
        "    # return the household\n",
        "    return household\n",
        "\n",
        "def remove_symbol_currency(currency):\n",
        "        '''Use this method to remove currency symbol\n",
        "            Args:\n",
        "                currency: df['Currency']\n",
        "            Return:\n",
        "                currency without symbol, example 'R$'\n",
        "        '''\n",
        "        if currency != '':\n",
        "          currency = float(currency.replace('R$ ', '').replace('.', '').replace(',', '.'))\n",
        "        return currency\n",
        "\n",
        "def first_order(df_orders):\n",
        "    '''Use this method to create primeira_compra column\n",
        "        Args:\n",
        "            df_orders: df_orders\n",
        "        Return:\n",
        "            df_orders with primeira_compra column\n",
        "    '''\n",
        "    # create auxiliar df with email and data_do_pedido column\n",
        "    df_aux = df_orders[['email', 'data_do_pedido']]\n",
        "    # group df by email and take retailer first order\n",
        "    df_aux = df_aux.groupby('email').agg(primeira_compra=('data_do_pedido', 'min')).reset_index()\n",
        "    # to do left join between df_orders and df_aux using email column\n",
        "    df_orders = df_orders.merge(df_aux, how='left', on='email')\n",
        "    # transform primeira_compra column in boolean value\n",
        "    df_orders['primeira_compra'] = df_orders['data_do_pedido'] == df_orders['primeira_compra']\n",
        "    return df_orders\n",
        "\n",
        "def index_order(df_orders):\n",
        "    '''Use this method to create index_order column\n",
        "        Args:\n",
        "            df_orders: df_orders\n",
        "        Return:\n",
        "            df_orders wiht index_order column\n",
        "    '''\n",
        "    # create auxiliar df with email, data_do_pedido and pedido column\n",
        "    df_aux = df_orders[['email', 'data_do_pedido', 'pedido']]\n",
        "    # group df by email and create a rank ascending based in data_do_pedido\n",
        "    df_aux['index_order'] = df_aux.groupby('email')['data_do_pedido'].rank(method='first')\n",
        "    # sort value by email and index_order\n",
        "    df_aux = df_aux.sort_values(by=['email', 'index_order'])\n",
        "    # drop column data_do_pedido\n",
        "    df_aux.drop(columns='data_do_pedido', axis=1, inplace=True)\n",
        "    # to do left join between df_orders and df_aux using email and pedido column\n",
        "    df_orders = df_orders.merge(df_aux, how='left', on=['email', 'pedido'])\n",
        "\n",
        "    return df_orders\n",
        "\n",
        "def remove_especial_charcter(x):\n",
        "  x = unidecode(x).lower()\n",
        "  return x\n",
        "\n",
        "def ticket_medio(df_orders):\n",
        "    df_ticket_medio = df_orders[['email', 'pedido', 'sub_total']]\n",
        "    df_ticket_medio = df_ticket_medio.groupby('email').agg(\n",
        "        n_total_pedidos=('pedido', 'nunique'),\n",
        "        sub_total=('sub_total', 'sum')\n",
        "    ).reset_index()\n",
        "    df_ticket_medio['ticket_medio'] = df_ticket_medio['sub_total']/df_ticket_medio['n_total_pedidos']\n",
        "    df_ticket_medio = df_ticket_medio[['email', 'ticket_medio']]\n",
        "    return df_ticket_medio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzktxk2WEnw5"
      },
      "outputs": [],
      "source": [
        "def format_df_registered(df_registered):\n",
        "  df_registered = rename_columns(df_registered)\n",
        "\n",
        "  column_mapping_portuguese = {\n",
        "            'street':'endereco',\n",
        "            'number':'numero',\n",
        "            'complement':'complemento',\n",
        "            'district':'bairro',\n",
        "            'city':'cidade',\n",
        "            'state':'estado',\n",
        "            'registered_date':'data_de_cadastro',\n",
        "            'number': 'numero'\n",
        "    }\n",
        "\n",
        "  # to get all columns\n",
        "  all_columns = df_registered.columns\n",
        "\n",
        "  # loop to change name columns to portuguese\n",
        "  for column in all_columns:\n",
        "      # try get value based in column\n",
        "      try:\n",
        "          column_to_rename = column_mapping_portuguese[column]\n",
        "      # case can't column_to_rename is column\n",
        "      except:\n",
        "          column_to_rename = column\n",
        "      # rename column\n",
        "      df_registered.rename(columns={\n",
        "          f'{column}':f'{column_to_rename}'\n",
        "      }, inplace=True)\n",
        "\n",
        "  # loop that take only column per time:\n",
        "  for column in all_columns:\n",
        "      # drop all column that donst is in list\n",
        "      if column not in ['email', 'endereco', 'numero', 'complemento', 'bairro', 'estado', 'cidade', 'data_de_cadastro']:\n",
        "          df_registered.drop(columns=f'{column}', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "  # take all columns after drop the coluns that will be use\n",
        "  all_columns = df_registered.columns\n",
        "\n",
        "  # list with possible names\n",
        "  columns_date = ['data']\n",
        "  columns_address = ['endereco', 'numero', 'complemento']\n",
        "\n",
        "  # list to take columns to format address\n",
        "  columns_address_format = []\n",
        "\n",
        "  # columns in right order\n",
        "  right_order = ['endereco', 'numero', 'complemento']\n",
        "\n",
        "  # loop to take  only column per time:\n",
        "  for column in all_columns:\n",
        "\n",
        "    # if column is in columns_date format date\n",
        "    if any(keyword in column for keyword in columns_date):\n",
        "        df_registered[column] = pd.to_datetime(df_registered[column].apply(format_date))\n",
        "    # if column is in columns_address add in columns_address_format\n",
        "    elif any(keyword in column for keyword in columns_address):\n",
        "        columns_address_format.append(column)\n",
        "\n",
        "  df_address = df_registered[columns_address_format]\n",
        "\n",
        "  df_registered[['numero', 'complemento', 'endereco']] = df_address.apply(lambda row: pd.Series(format_address(row['endereco'], row['numero'], row['complemento'])), axis=1)\n",
        "\n",
        "  df_registered['tipo_morada'] = df_registered['complemento'].apply(household_type)\n",
        "\n",
        "  df_registered['cidade'] = df_registered['cidade'].apply(remove_especial_charcter)\n",
        "\n",
        "  return df_registered\n",
        "\n",
        "def format_df_order(df_orders):\n",
        "    '''Use this method to restructure order dataframe\n",
        "        Args:\n",
        "            df_orders: dataframe with orders\n",
        "        Return:\n",
        "            df_orders: df_orders rename columns and only need columns\n",
        "    '''\n",
        "    # rename columns\n",
        "    df_orders = rename_columns(df_orders)\n",
        "\n",
        "    # get all columns\n",
        "    all_columns = df_orders.columns\n",
        "    # loop to drop all columns that dont go use\n",
        "    for column in all_columns:\n",
        "        # drop all column that donst is in list\n",
        "        if column not in ['email', 'pedido', 'data_do_pedido', 'dia_do_pedido', 'quantidade_de_itens', 'código_kitprato', 'codigo_produto_simples', 'produtos', 'qtd_produtos', 'valor_unitario', 'sub_total', 'valor_descontos', 'valor_frete', 'valor_total', 'forma_de_entrega', 'forma_de_pagamento']:\n",
        "          try:\n",
        "            df_orders.drop(columns=f'{column}', axis=1, inplace=True)\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "    #create primeira_compra column\n",
        "    df_orders = first_order(df_orders)\n",
        "\n",
        "    # create index_order column\n",
        "    df_orders = index_order(df_orders)\n",
        "\n",
        "    for column in ['valor_unitario', 'sub_total', 'valor_descontos', 'valor_frete', 'valor_total']:\n",
        "      df_orders[column] = df_orders[column].apply(remove_symbol_currency)\n",
        "\n",
        "    # return dataframe adjusted\n",
        "    return df_orders\n",
        "\n",
        "def create_table_month(df_registered, df_orders):\n",
        "  # format date to monday\n",
        "  df_registered['data_de_cadastro'] = pd.to_datetime(df_registered['data_de_cadastro'])\n",
        "  df_registered['mes'] = df_registered['data_de_cadastro'].apply(lambda x: x.strftime(\"%m/01/%Y\"))\n",
        "  df_orders['data_do_pedido'] = pd.to_datetime(df_orders['data_do_pedido'])\n",
        "  df_orders['mes'] = df_orders['data_do_pedido'].apply(lambda x: x.strftime('%m/01/%Y'))\n",
        "  # transform column sub_total in float\n",
        "  df_orders['sub_total'] = df_orders['sub_total'].astype(float)\n",
        "  df_orders['index_order'] = df_orders['index_order'].astype(int)\n",
        "  # unique count per registered month\n",
        "  df_cadastro_total = df_registered.groupby('mes').agg(total_cadastro=('email', 'nunique')).reset_index()\n",
        "  # unique count email with ticket_medio = '' per registered_month\n",
        "  df_cadastro_sem_compra = df_registered[df_registered['ticket_medio'].isna()].groupby('mes').agg(cadastro_sem_compra=('email','nunique')).reset_index()\n",
        "  # avarage value first order per month\n",
        "  df_avg_value_first_order = df_orders[df_orders['index_order']==1].groupby('mes').agg(avg_value_first_order=('sub_total','mean')).reset_index()\n",
        "  df_avg_value_first_order['avg_value_first_order'] = df_avg_value_first_order['avg_value_first_order'].round(2)\n",
        "  # avarage value to retention\n",
        "  df_avg_value_retention_order = df_orders[df_orders['index_order']>1].groupby('mes').agg(total_retention=('sub_total','sum'), total_orders=('pedido','nunique')).reset_index()\n",
        "  df_avg_value_retention_order['avg_value_retention'] = round(df_avg_value_retention_order['total_retention']/df_avg_value_retention_order['total_orders'],2)\n",
        "  df_avg_value_retention_order.drop(columns=['total_retention', 'total_orders'], inplace=True)\n",
        "  # avarage ticket_medio per month\n",
        "  df_avg_ticket_medio = df_orders.groupby('mes').agg(total_retention=('sub_total','sum'), total_orders=('pedido','nunique')).reset_index()\n",
        "  df_avg_ticket_medio['avg_ticket_medio'] = round(df_avg_ticket_medio['total_retention']/df_avg_ticket_medio['total_orders'],2)\n",
        "  df_avg_ticket_medio.drop(columns=['total_retention', 'total_orders'], inplace=True)\n",
        "  # merge all df\n",
        "  df_consolidated_month = df_cadastro_total.merge(df_cadastro_sem_compra, how='left', on='mes')\n",
        "  df_consolidated_month = df_consolidated_month.merge(df_avg_value_first_order, how='left', on='mes')\n",
        "  df_consolidated_month = df_consolidated_month.merge(df_avg_value_retention_order, how='left', on='mes')\n",
        "  df_consolidated_month = df_consolidated_month.merge(df_avg_ticket_medio, how='left', on='mes')\n",
        "  df_consolidated_month['cadastro_com_compra'] = df_consolidated_month['total_cadastro'] - df_consolidated_month['cadastro_sem_compra']\n",
        "  df_consolidated_month['porc_retailer_com_compra'] = round(df_consolidated_month['cadastro_com_compra']/df_consolidated_month['total_cadastro']*100,2)\n",
        "  df_consolidated_month.fillna(0, inplace=True)\n",
        "  new_order = ['mes', 'total_cadastro', 'cadastro_sem_compra', 'avg_value_first_order', 'avg_value_retention', 'avg_ticket_medio', 'cadastro_com_compra','porc_retailer_com_compra']\n",
        "  df_consolidated_month = df_consolidated_month[new_order]\n",
        "\n",
        "  return df_consolidated_month\n",
        "\n",
        "def create_cohort_table(df_registered, df_orders):\n",
        "  # Pegar somente a data do segundo pedido\n",
        "  df_retencao_cohort = df_orders[df_orders['index_order'] == 2][['email','data_do_pedido']]\n",
        "  # Pegar a data de registro\n",
        "  df_registered_cohort = df_registered[['email', 'data_de_cadastro']]\n",
        "  # Trunc para mês\n",
        "  df_registered_cohort['cohort'] = df_registered_cohort['data_de_cadastro'].dt.strftime('%m/01/%Y')\n",
        "  # Dropar a coluna data_de_cadastro\n",
        "  df_registered_cohort.drop(columns='data_de_cadastro', axis=1, inplace=True)\n",
        "  # Trunc para mês\n",
        "  df_retencao_cohort['mes'] = df_retencao_cohort['data_do_pedido'].dt.strftime('%m/01/%Y')\n",
        "  # Left join entre df_retencao_cohort e df_registered_cohort\n",
        "  df_retencao_cohort = df_retencao_cohort.merge(df_registered_cohort, how='left', on='email')\n",
        "  # Pegar todas as order maior ou igual a 2\n",
        "  df_retencao_cohort_other = df_orders[df_orders['index_order'] >= 2][['email','data_do_pedido']]\n",
        "  # Trunc para mês\n",
        "  df_retencao_cohort_other['mes_other'] = df_retencao_cohort_other['data_do_pedido'].dt.strftime('%m/01/%Y')\n",
        "  # Dropar a coluna data_do_pedido\n",
        "  df_retencao_cohort_other.drop(columns='data_do_pedido', axis=1, inplace=True)\n",
        "  # Left join entre df_retencao_cohort e df_retencao_cohort_other usando email\n",
        "  df_retencao_cohort = df_retencao_cohort.merge(df_retencao_cohort_other, how='left', on='email')\n",
        "  # calculando os meses\n",
        "  df_retencao_cohort['mes'] = round((pd.to_datetime(df_retencao_cohort['mes_other']) - pd.to_datetime(df_retencao_cohort['mes'])).dt.days/30,0)\n",
        "  # transforma em número inteiro\n",
        "  df_retencao_cohort['mes'] = df_retencao_cohort['mes'].astype(int)\n",
        "  # Dropa as colunas data_do_pedido e mes_other\n",
        "  df_retencao_cohort.drop(columns=['data_do_pedido', 'mes_other'], axis=1, inplace=True)\n",
        "  # Calcula o Total de cada cohort\n",
        "  df_total_cohort = df_retencao_cohort.groupby('cohort').agg(total=('email', 'nunique')).reset_index()\n",
        "  # Calcula o total por mes\n",
        "  df_mes = df_retencao_cohort.groupby(['cohort', 'mes']).agg(n_recompra=('email', 'nunique')).reset_index()\n",
        "  # Left join entre df_total_cohort e df_mes usando o cohort\n",
        "  df_retencao_cohort = df_total_cohort.merge(df_mes, how='left', on='cohort')\n",
        "  # Calcual % de recompra por cohort\n",
        "  df_retencao_cohort['n_recompra'] = round(df_retencao_cohort['n_recompra']/df_retencao_cohort['total']*100,0)\n",
        "  # tira os meses iniciais\n",
        "  df_retencao_cohort = df_retencao_cohort[df_retencao_cohort['mes'] > 0]\n",
        "\n",
        "  return df_retencao_cohort\n",
        "\n",
        "def create_year_table(df_registered, df_orders):\n",
        "  data_atual = datetime.today().date()\n",
        "  columns = ['ano', 'tempo_retencao', 'ticket_medio']\n",
        "  dados_temp = []\n",
        "  df_aux = pd.DataFrame(columns=columns)\n",
        "\n",
        "  df_take_year = list(set(list(pd.to_datetime(df_registered['data_de_cadastro']).dt.strftime('%Y'))))\n",
        "  df_take_year.remove(str(data_atual.year))\n",
        "\n",
        "  df_ano = df_registered[['email', 'data_de_cadastro']]\n",
        "  # format data_de_cadastro to datetime\n",
        "  df_ano['data_de_cadastro'] =  pd.to_datetime(df_ano['data_de_cadastro'])\n",
        "  # take date order\n",
        "  df_compra_email = df_orders[['email','data_do_pedido', 'index_order', 'pedido', 'sub_total']]\n",
        "  # format data_do_petido to datetime\n",
        "  df_compra_email['data_do_pedido'] = pd.to_datetime(df_compra_email['data_do_pedido'])\n",
        "  df_compra_email['sub_total'] = df_compra_email['sub_total'].astype(float)\n",
        "  for ano in df_take_year:\n",
        "    # set start period\n",
        "    periodo_inicial = f'{ano}-01-01'\n",
        "    # set final period\n",
        "    periodo_final = f'{ano}-12-31'\n",
        "    # filter df_ano to between start and final period, take retailer that registered between this periods\n",
        "    df_aux_ano = df_ano[(df_ano['data_de_cadastro'] >= periodo_inicial) & (df_ano['data_de_cadastro'] <= periodo_final)]\n",
        "    # filter to take second order between start and final period\n",
        "    df_compra_seg = df_compra_email[(df_compra_email['index_order']==2) & (df_compra_email['data_do_pedido'] >= periodo_inicial) & (df_compra_email['data_do_pedido'] <= periodo_final)][['email', 'data_do_pedido']]\n",
        "    # filter to take last order between start and final period\n",
        "    df_compra_ult = df_compra_email[(df_compra_email['data_do_pedido'] >= periodo_inicial) & (df_compra_email['data_do_pedido'] <= periodo_final)].groupby('email').agg(ult_compra=('data_do_pedido', 'max')).reset_index()\n",
        "    # filter to take ticket medio between start and final period\n",
        "    df_ticket_mean = df_compra_email[(df_compra_email['data_do_pedido'] >= periodo_inicial) & (df_compra_email['data_do_pedido'] <= periodo_final)].groupby('email').agg(\n",
        "        n_pedidos=('pedido', 'nunique'),\n",
        "        total = ('sub_total', 'sum')\n",
        "    ).reset_index()\n",
        "    # calculate avarage ticket\n",
        "    df_ticket_mean['ticket_medio'] = df_ticket_mean['total']/df_ticket_mean['n_pedidos']\n",
        "    # drop columns that will be used\n",
        "    df_ticket_mean.drop(columns=['n_pedidos', 'total'], axis=1, inplace=True)\n",
        "    # left join between df_compra_seg and df_compra_ult using email\n",
        "    df_compra = df_compra_seg.merge(df_compra_ult, how='left', on='email')\n",
        "    # left join between df_aux_ano and df_compra using email\n",
        "    df_aux_ano = df_aux_ano.merge(df_compra, how='left', on='email')\n",
        "    # left join between df_aux_ano and df_ticket_mean using email\n",
        "    df_aux_ano = df_aux_ano.merge(df_ticket_mean, how='left', on='email')\n",
        "    # set columns dias_sem_compra is final period\n",
        "    df_aux_ano['dias_sem_compra'] = periodo_final\n",
        "    # format dias_sem_compra to datetime\n",
        "    df_aux_ano['dias_sem_compra'] = pd.to_datetime(df_aux_ano['dias_sem_compra'])\n",
        "    # calculate diference between final peiod and last order\n",
        "    df_aux_ano['dias_sem_compra'] = (df_aux_ano['dias_sem_compra'] - df_aux_ano['ult_compra']).dt.days\n",
        "    # calculate avarage of days without order\n",
        "    media_dias_sem_compra = df_aux_ano['dias_sem_compra'].mean()\n",
        "    # take all retailer with dias_sem_compra less then media_dias_sem_compra\n",
        "    df_aux_ano = df_aux_ano[df_aux_ano['dias_sem_compra'] < media_dias_sem_compra]\n",
        "    # filter to take all retailers that are with data_do_pedido is not null\n",
        "    df_aux_ano = df_aux_ano[~df_aux_ano['data_do_pedido'].isna()]\n",
        "    # calculate retention months\n",
        "    df_aux_ano['tempo_de_retencao'] = (df_aux_ano['ult_compra'] - df_aux_ano['data_do_pedido']).dt.days /30\n",
        "    # add one in tempo_de_retencao because retailer dont do 0 month that dont purchase but yes 1 month\n",
        "    df_aux_ano['tempo_de_retencao'] = df_aux_ano['tempo_de_retencao'].round(0) + 1\n",
        "    # calculate avarage of the retention time\n",
        "    tempo_mr = round(df_aux_ano['tempo_de_retencao'].mean(),0)\n",
        "    # calculate avatage of the avarage ticket\n",
        "    avarage_ticket = round(df_aux_ano['ticket_medio'].mean(),0)\n",
        "    # add data in a dictionary and in list\n",
        "    dados_temp.append({'ano': ano, 'tempo_retencao': tempo_mr, 'ticket_medio':avarage_ticket})\n",
        "    # create dataframe this list\n",
        "    df_temp = pd.DataFrame(dados_temp)\n",
        "    # concat with auxiliar dataframe\n",
        "    df_aux = pd.concat([df_aux, df_temp])\n",
        "\n",
        "  # drop duplicates\n",
        "  df_ltv_ano = df_aux.drop_duplicates()\n",
        "  # calculate LTV\n",
        "  df_ltv_ano['LTV'] = df_ltv_ano['ticket_medio']*df_ltv_ano['tempo_retencao']\n",
        "  # remove all null\n",
        "  df_ltv_ano = df_ltv_ano[~df_ltv_ano['LTV'].isna()]\n",
        "  # format LTV\n",
        "  df_ltv_ano['LTV'] = df_ltv_ano['LTV'].round(2)\n",
        "\n",
        "  columns = ['ano', 'churn']\n",
        "  dados_temp = []\n",
        "  df_aux = pd.DataFrame(columns=columns)\n",
        "\n",
        "  for ano in df_take_year:\n",
        "    # set start period\n",
        "    periodo_inicial = f'{ano}-01-01'\n",
        "    # set final period\n",
        "    periodo_final = f'{ano}-12-31'\n",
        "    # filter df_ano to between start and final period, take retailer that registered between this periods\n",
        "    df_cadastro_ano = df_ano[(df_ano['data_de_cadastro'] >= periodo_inicial) & (df_ano['data_de_cadastro'] <= periodo_final)]\n",
        "    # total registered in year\n",
        "    total_cadastrado_ano = df_cadastro_ano['email'].nunique()\n",
        "    # filter order between star and final period\n",
        "    df_ult_compra_ano = df_compra_email[(df_compra_email['data_do_pedido'] >= periodo_inicial) & (df_compra_email['data_do_pedido'] <= periodo_final)][['email', 'data_do_pedido']]\n",
        "    # take last order\n",
        "    df_ult_compra_ano = df_ult_compra_ano.groupby('email').agg(ult_compra=('data_do_pedido', 'max')).reset_index()\n",
        "    # create data_atual column\n",
        "    df_ult_compra_ano['data_atual'] = periodo_final\n",
        "    # format column to datetime\n",
        "    df_ult_compra_ano['data_atual'] = pd.to_datetime(df_ult_compra_ano['data_atual'])\n",
        "    # calculate days without order\n",
        "    df_ult_compra_ano['dias_sem_compra'] = (df_ult_compra_ano['data_atual'] - df_ult_compra_ano['ult_compra']).dt.days\n",
        "    # calculate avarage days without order\n",
        "    df_media_dias = df_ult_compra_ano[['email', 'dias_sem_compra']]\n",
        "    dias_sem_compra = df_media_dias['dias_sem_compra'].mean()\n",
        "    # take only retailers with days without order less then avarage days without order\n",
        "    df_ult_compra_ano = df_ult_compra_ano[df_ult_compra_ano['dias_sem_compra'] < dias_sem_compra]\n",
        "    # take tempo_retencao from df_ltv_ano\n",
        "    df_ltv_ano_aux = df_ltv_ano[df_ltv_ano['ano'] == ano]\n",
        "    tempo_medio_de_retencao = df_ltv_ano_aux['tempo_retencao'].mean()\n",
        "    # format final period to datetime\n",
        "    periodo_final = pd.to_datetime(periodo_final)\n",
        "    # calculate time wihtout order\n",
        "    df_ult_compra_ano['tempo_sem_compra'] = (periodo_final - df_ult_compra_ano['ult_compra']).dt.days/30\n",
        "    # verify if client is lost\n",
        "    df_ult_compra_ano['cliente_perdido'] = np.where(df_ult_compra_ano['tempo_sem_compra'] >= tempo_medio_de_retencao, True, False)\n",
        "    # calculate total retailer lost\n",
        "    total_perdido_ano = df_ult_compra_ano[df_ult_compra_ano['cliente_perdido'] == True]['email'].nunique()\n",
        "    # calculate churn\n",
        "    churn_ano = round(total_perdido_ano/total_cadastrado_ano*100,2)\n",
        "    # create temp dataframe\n",
        "    dados_temp.append({'ano': ano, 'churn': churn_ano})\n",
        "    df_temp = pd.DataFrame(dados_temp)\n",
        "    df_aux = pd.concat([df_aux, df_temp])\n",
        "  # drop duplicates\n",
        "  df_churn_ano = df_aux.drop_duplicates()\n",
        "  # sort values by ano\n",
        "  df_churn_ano.sort_values(by='ano', inplace=True)\n",
        "\n",
        "  df_merge = df_ltv_ano.merge(df_churn_ano, how='left', on='ano')\n",
        "  df_merge['coluna'] = ''\n",
        "  df_merge['churn'] = df_merge['churn'].astype(str)\n",
        "\n",
        "  return df_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mf5V7N7eShg"
      },
      "outputs": [],
      "source": [
        "def carregando(): #function to \"show\" that is loading\n",
        "    i = 0\n",
        "    while i < 3:\n",
        "        time.sleep(0.8)\n",
        "        if i == 2:\n",
        "          print('.')\n",
        "        else:\n",
        "          print('.', end='', flush=True)\n",
        "        i += 1\n",
        "\n",
        "def gerar_id_unico():\n",
        "    caracteres = string.ascii_letters + string.digits  # letras maiúsculas, minúsculas e números\n",
        "    id_unico = ''.join(random.choice(caracteres) for _ in range(12))\n",
        "    return id_unico\n",
        "\n",
        "def verificar_existencia(id_gerado, ids_existentes):\n",
        "    return id_gerado in ids_existentes\n",
        "\n",
        "def new_retailer(name): # main fuction to create new retailers\n",
        "  name = name.lower() # take lower name\n",
        "\n",
        "  print('\\nAbrindo a pasta share', end='', flush=True)\n",
        "  carregando()\n",
        "  folder_id, folder_id_raw, df_retailer = get_all_folders(name) # get all folder that is in folder with name\n",
        "\n",
        "  print('\\nPegando os arquivos', end='', flush=True)\n",
        "  carregando()\n",
        "\n",
        "  if len(folder_id) > 1: # verify if this folder has more than 1 archive\n",
        "    print('\\nEsse e-commerce já tem as pastas padrão')\n",
        "    erro = True\n",
        "    return erro\n",
        "\n",
        "  for folder in folder_id: # take folder id with share base\n",
        "    if 'share' in folder['name']:\n",
        "      folder_id = folder['id']\n",
        "\n",
        "  id_retailers = list(set(list(df_retailer['id'])))\n",
        "\n",
        "  dict_retailer = {}\n",
        "\n",
        "  id_gerado = gerar_id_unico()\n",
        "  while verificar_existencia(id_gerado, id_retailers):\n",
        "    id_gerado = gerar_id_unico()\n",
        "  dict_retailer['id'] = f'{id_gerado}'\n",
        "  dict_retailer['nome_da_empresa'] = f'{name}'\n",
        "  dict_retailer['email'] = ''\n",
        "  dict_retailer['telefone'] = ''\n",
        "  dict_retailer['nome'] = ''\n",
        "  dict_retailer['cnpj'] = ''\n",
        "  print(dict_retailer)\n",
        "\n",
        "  erro = False\n",
        "\n",
        "#   name_share_archives = take_archives(folder_id) # take name of the share archives\n",
        "\n",
        "#   print('\\nCriando as tabelas', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_registered, df_orders = read_gsheets(name_share_archives) # read gsheets and input in dataframe\n",
        "\n",
        "#   print('\\nFormatando a tabela de clientes', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_registered = format_df_registered(df_registered) # format df_registered\n",
        "\n",
        "#   print('\\nFormatando a tabela de pedidos', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_order = format_df_order(df_orders) # format df_order\n",
        "\n",
        "#   raw_name = f'raw_{name}' # is folder name\n",
        "#   print(f'\\nCriando a Pasta \"{raw_name}\"', end='', flush=True)\n",
        "#   carregando()\n",
        "\n",
        "#   folder_raw_id = create_folder(folder_id_raw, raw_name) # take folder id\n",
        "#   print('\\nBaixando o arquivo da tabela de clientes', end='', flush=True)\n",
        "#   carregando()\n",
        "\n",
        "#   df_registered = df_registered.merge(ticket_medio(df_order), how='left', on='email') # calculate avarage order value and doing left join with df_registered\n",
        "\n",
        "#   df_registered['data_de_cadastro'] = df_registered['data_de_cadastro'].apply(format_date) # fomat to datetime data_de_cadastro column\n",
        "#   df_registered.to_csv('df_retialer.csv') # creating csv to df_registered\n",
        "\n",
        "#   print('\\nBaixando o arquivo da tabela de pedidos', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_order['data_do_pedido'] = df_order['data_do_pedido'].apply(format_date) # format to datetime data_do_pedido column\n",
        "#   df_order.to_csv('df_order.csv') # creating csv to df_order\n",
        "\n",
        "#   core_name = f'core_{name}' # is core folder name\n",
        "\n",
        "# #### comentar o resto do código\n",
        "\n",
        "#   print(f'\\nCriando a Pasta \"{core_name}\"', end='', flush=True)\n",
        "#   carregando()\n",
        "#   folder_core_id = create_folder(folder_id_raw, core_name)\n",
        "#   print(f'\\nCriando a tabela \"month_{name}_table_{data_atual}\"', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_consolidated_month = create_table_month(df_registered, df_order)\n",
        "#   print(f'\\nCriando a tabela \"year_{name}_table_{data_atual}\"', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_year = create_year_table(df_registered, df_order)\n",
        "#   print(f'\\nCriando a tabela \"cohort_{name}_table_{data_atual}\"', end='', flush=True)\n",
        "#   carregando()\n",
        "#   df_cohort = create_cohort_table(df_registered, df_order)\n",
        "#   print(f'\\nColando os dados no google sheets', end='', flush=True)\n",
        "#   carregando()\n",
        "#   name_sheets = f'month_{name}_table_{data_atual}'\n",
        "#   create_gsheets(folder_core_id, name_sheets, df_consolidated_month)\n",
        "#   print(f'\\nTabela \"{name_sheets}\" pronta!')\n",
        "#   name_sheets = f'cohort_{name}_table_{data_atual}'\n",
        "#   create_gsheets(folder_core_id, name_sheets, df_cohort)\n",
        "#   print(f'\\nTabela \"{name_sheets}\" pronta!')\n",
        "#   name_sheets = f'year_{name}_table_{data_atual}'\n",
        "#   create_gsheets(folder_core_id, name_sheets, df_year)\n",
        "#   print(f'\\nTabela \"{name_sheets}\" pronta!')\n",
        "#   erro = False\n",
        "  # return erro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "5ElfXoDYca0G",
        "outputId": "d24b296a-3438-48c8-f0cc-bffadc6f401f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "É um cliente novo?\n",
            "R: sim\n",
            "\n",
            "Arquivos de qual e-commerce você quer?\n",
            "R: teste\n",
            "\n",
            "Abrindo a pasta share...\n",
            "\n",
            "Pegando os arquivos...\n",
            "{'id': '6JHqle7ByvTO', 'name': 'teste'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-8fb6dc5e1bc0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0merro\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nArquivos de qual e-commerce você quer?\\nR: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_retailer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "data_atual = str(data_atual).replace('-','_')\n",
        "\n",
        "erro_first_answer = True\n",
        "while erro_first_answer == True:\n",
        "  is_new = input('É um cliente novo?\\nR: ')\n",
        "  if is_new.lower() in ['sim', 'yes']:\n",
        "    while erro == True:\n",
        "      name = input('\\nArquivos de qual e-commerce você quer?\\nR: ')\n",
        "      if name != '':\n",
        "        new_retailer(name)\n",
        "  elif is_new.lower() in ['não', 'nao', 'No', 'no']:\n",
        "    name = input('\\nArquivos de qual e-commerce você quer?\\nR:n')\n",
        "    try:\n",
        "        name = name.lower()\n",
        "        print('\\nAbrindo a pasta share', end='', flush=True)\n",
        "        carregando()\n",
        "        folder_id, folder_id_raw = get_all_folders(name)\n",
        "        for folder in folder_id:\n",
        "          if 'share' in folder['name']:\n",
        "            folder_id = folder['id']\n",
        "        print('\\nPegando os arquivos', end='', flush=True)\n",
        "        carregando()\n",
        "        name_share_archives = take_archives(folder_id)\n",
        "        print(name_share_archives)\n",
        "        erro = False\n",
        "    except:\n",
        "      print('Pasta não encontrada, vamos tentar novamente?')\n",
        "  else:\n",
        "    print('\\n Resposta aparenta não estar correta! \\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkELD6eca8oLiuTD/KYB8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}